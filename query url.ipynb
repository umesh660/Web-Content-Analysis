{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eecd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e96f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2668ecad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.0.5)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (0.1.21)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (1.24.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.87)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bd99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50c6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f061be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 2/2 [00:01<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbacf99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', '.', ','],\n",
    "    chunk_size=1000\n",
    ")\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c672fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (0.1.21)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (1.24.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.87)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1fb39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a57d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51bf7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore_openai = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68247ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eef6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"To avoid shortcutting and copying Ho much do  they randomly mask of past tokens during training.\"\n",
    "docs = vectorstore_openai.similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4284c4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}),\n",
       " Document(page_content='<p>To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.</p>\\n<p>The training dataset in their experiments is a combination of <a href=\"https://huggingface.co/datasets/openai/webgpt_comparisons\">WebGPT comparisons</a>, <a href=\"https://github.com/openai/summarize-from-feedback\">summarization from human feedback</a> and <a href=\"https://github.com/anthropics/hh-rlhf\">human preference dataset</a>.</p>\\n<img src=\"CoH.png\" style=\"width: 100%;\" class=\"center\" />\\n<figcaption>Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: <a href=\"https://arxiv.org/abs/2302.02676\" target=\"_blank\">Liu et al. 2023</a>)</figcaption>', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}),\n",
       " Document(page_content='<p>They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, <em>knowing when to and how to use the tools are crucial</em>, determined by the LLM capability.</p>', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}),\n",
       " Document(page_content='.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5b86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a44d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
